import pandas as pd
import numpy as np
df = pd.read_csv("/content/winequality-red.csv")
df
fixed acidity	volatile acidity	citric acid	residual sugar	chlorides	free sulfur dioxide	total sulfur dioxide	density	pH	sulphates	alcohol	quality
0	7.4	0.700	0.00	1.9	0.076	11.0	34.0	0.99780	3.51	0.56	9.4	5
1	7.8	0.880	0.00	2.6	0.098	25.0	67.0	0.99680	3.20	0.68	9.8	5
2	7.8	0.760	0.04	2.3	0.092	15.0	54.0	0.99700	3.26	0.65	9.8	5
3	11.2	0.280	0.56	1.9	0.075	17.0	60.0	0.99800	3.16	0.58	9.8	6
4	7.4	0.700	0.00	1.9	0.076	11.0	34.0	0.99780	3.51	0.56	9.4	5
...	...	...	...	...	...	...	...	...	...	...	...	...
1594	6.2	0.600	0.08	2.0	0.090	32.0	44.0	0.99490	3.45	0.58	10.5	5
1595	5.9	0.550	0.10	2.2	0.062	39.0	51.0	0.99512	3.52	0.76	11.2	6
1596	6.3	0.510	0.13	2.3	0.076	29.0	40.0	0.99574	3.42	0.75	11.0	6
1597	5.9	0.645	0.12	2.0	0.075	32.0	44.0	0.99547	3.57	0.71	10.2	5
1598	6.0	0.310	0.47	3.6	0.067	18.0	42.0	0.99549	3.39	0.66	11.0	6
1599 rows Ã— 12 columns
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1599 entries, 0 to 1598
Data columns (total 12 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   fixed acidity         1599 non-null   float64
 1   volatile acidity      1599 non-null   float64
 2   citric acid           1599 non-null   float64
 3   residual sugar        1599 non-null   float64
 4   chlorides             1599 non-null   float64
 5   free sulfur dioxide   1599 non-null   float64
 6   total sulfur dioxide  1599 non-null   float64
 7   density               1599 non-null   float64
 8   pH                    1599 non-null   float64
 9   sulphates             1599 non-null   float64
 10  alcohol               1599 non-null   float64
 11  quality               1599 non-null   int64  
dtypes: float64(11), int64(1)
memory usage: 150.0 KB
x = df.iloc[:,:11].values
array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],
       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],
       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],
       ...,
       [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],
       [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],
       [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]])
y = df.iloc[:,11].values
y
array([5, 5, 5, ..., 6, 5, 6])
from sklearn.model_selection import train_test_split
train_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.2, random_state=0)
from sklearn.linear_model import LinearRegression
Lin = LinearRegression()
Lin.fit(train_x, train_y)
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
pread_y = Lin.predict(test_x)
pread_y2 = np.round_(pread_y)
pread_y2
array([6., 5., 7., 5., 6., 5., 5., 6., 5., 5., 5., 5., 6., 5., 6., 6., 7.,
       6., 6., 5., 6., 5., 6., 6., 5., 5., 5., 6., 5., 6., 6., 6., 6., 5.,
       6., 6., 5., 5., 6., 6., 5., 6., 7., 7., 6., 5., 5., 6., 5., 6., 5.,
       5., 6., 6., 6., 5., 5., 5., 7., 5., 5., 6., 6., 6., 5., 6., 5., 6.,
       6., 6., 5., 5., 5., 6., 6., 6., 5., 5., 6., 6., 6., 5., 6., 6., 6.,
       5., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 6., 5., 5., 6., 7., 6.,
       6., 6., 6., 5., 6., 5., 6., 5., 6., 5., 6., 5., 6., 6., 6., 6., 6.,
       6., 5., 6., 5., 5., 6., 6., 5., 5., 6., 6., 5., 5., 6., 6., 6., 5.,
       6., 5., 6., 5., 6., 5., 5., 5., 6., 6., 6., 6., 6., 5., 6., 6., 5.,
       6., 6., 5., 5., 5., 6., 6., 6., 6., 6., 5., 6., 5., 6., 6., 5., 6.,
       6., 6., 5., 7., 6., 6., 6., 7., 6., 5., 5., 7., 5., 6., 7., 5., 6.,
       6., 5., 6., 6., 6., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 5., 5.,
       5., 5., 5., 6., 6., 5., 6., 6., 5., 6., 5., 5., 6., 6., 6., 5., 5.,
       6., 6., 6., 5., 6., 6., 6., 5., 5., 5., 6., 5., 6., 6., 6., 6., 7.,
       7., 6., 5., 5., 5., 5., 6., 5., 6., 5., 5., 6., 5., 5., 5., 5., 6.,
       6., 5., 5., 5., 6., 5., 7., 5., 6., 5., 5., 5., 5., 6., 6., 6., 6.,
       6., 6., 6., 6., 6., 5., 7., 6., 5., 7., 6., 6., 6., 5., 6., 5., 6.,
       6., 6., 5., 6., 5., 5., 6., 6., 5., 5., 5., 6., 5., 5., 6., 6., 6.,
       5., 5., 6., 5., 6., 6., 5., 5., 5., 7., 6., 6., 5., 6.])
from sklearn.metrics import confusion_matrix, accuracy_score
accuracy_score(test_y, pread_y2)
0.63125
Lin.score(train_x, train_y)
0.36545196162068655
from sklearn.metrics import mean_absolute_error as mae
mae(test_y, pread_y2)
0.396875
df.corr()
fixed acidity	volatile acidity	citric acid	residual sugar	chlorides	free sulfur dioxide	total sulfur dioxide	density	pH	sulphates	alcohol	quality
fixed acidity	1.000000	-0.256131	0.671703	0.114777	0.093705	-0.153794	-0.113181	0.668047	-0.682978	0.183006	-0.061668	0.124052
volatile acidity	-0.256131	1.000000	-0.552496	0.001918	0.061298	-0.010504	0.076470	0.022026	0.234937	-0.260987	-0.202288	-0.390558
citric acid	0.671703	-0.552496	1.000000	0.143577	0.203823	-0.060978	0.035533	0.364947	-0.541904	0.312770	0.109903	0.226373
residual sugar	0.114777	0.001918	0.143577	1.000000	0.055610	0.187049	0.203028	0.355283	-0.085652	0.005527	0.042075	0.013732
chlorides	0.093705	0.061298	0.203823	0.055610	1.000000	0.005562	0.047400	0.200632	-0.265026	0.371260	-0.221141	-0.128907
free sulfur dioxide	-0.153794	-0.010504	-0.060978	0.187049	0.005562	1.000000	0.667666	-0.021946	0.070377	0.051658	-0.069408	-0.050656
total sulfur dioxide	-0.113181	0.076470	0.035533	0.203028	0.047400	0.667666	1.000000	0.071269	-0.066495	0.042947	-0.205654	-0.185100
density	0.668047	0.022026	0.364947	0.355283	0.200632	-0.021946	0.071269	1.000000	-0.341699	0.148506	-0.496180	-0.174919
pH	-0.682978	0.234937	-0.541904	-0.085652	-0.265026	0.070377	-0.066495	-0.341699	1.000000	-0.196648	0.205633	-0.057731
sulphates	0.183006	-0.260987	0.312770	0.005527	0.371260	0.051658	0.042947	0.148506	-0.196648	1.000000	0.093595	0.251397
alcohol	-0.061668	-0.202288	0.109903	0.042075	-0.221141	-0.069408	-0.205654	-0.496180	0.205633	0.093595	1.000000	0.476166
quality	0.124052	-0.390558	0.226373	0.013732	-0.128907	-0.050656	-0.185100	-0.174919	-0.057731	0.251397	0.476166	1.000000
x_a = df[[ 'fixed acidity','volatile acidity', 'citric acid','chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'sulphates','alcohol']].values
x_a
array([[ 7.4    ,  0.7    ,  0.     , ...,  0.9978 ,  0.56   ,  9.4    ],
       [ 7.8    ,  0.88   ,  0.     , ...,  0.9968 ,  0.68   ,  9.8    ],
       [ 7.8    ,  0.76   ,  0.04   , ...,  0.997  ,  0.65   ,  9.8    ],
       ...,
       [ 6.3    ,  0.51   ,  0.13   , ...,  0.99574,  0.75   , 11.     ],
       [ 5.9    ,  0.645  ,  0.12   , ...,  0.99547,  0.71   , 10.2    ],
       [ 6.     ,  0.31   ,  0.47   , ...,  0.99549,  0.66   , 11.     ]])
train_x, test_x, train_y, test_y = train_test_split(x_a,y, test_size=0.2, random_state=0)
Lin.fit(train_x, train_y)
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
pread_y3 = Lin.predict(test_x)
pread_y4 = np.round_(pread_y3)
pread_y4
array([6., 5., 7., 5., 6., 5., 5., 6., 5., 5., 5., 5., 6., 5., 6., 6., 7.,
       6., 6., 5., 6., 5., 6., 6., 6., 5., 5., 6., 5., 6., 6., 6., 6., 5.,
       6., 6., 5., 6., 6., 6., 5., 6., 7., 7., 6., 5., 5., 6., 6., 6., 5.,
       5., 6., 6., 6., 5., 5., 5., 7., 5., 5., 6., 6., 6., 5., 6., 5., 6.,
       6., 6., 5., 5., 5., 6., 6., 6., 5., 5., 6., 6., 6., 5., 6., 6., 5.,
       5., 6., 5., 5., 5., 5., 5., 6., 5., 6., 5., 6., 5., 5., 6., 7., 6.,
       6., 6., 6., 5., 6., 5., 6., 5., 6., 5., 6., 5., 6., 6., 6., 6., 6.,
       6., 5., 6., 5., 5., 6., 6., 5., 5., 6., 6., 5., 5., 6., 6., 6., 5.,
       6., 5., 6., 5., 6., 5., 5., 5., 6., 6., 6., 6., 6., 5., 6., 6., 5.,
       5., 6., 5., 5., 5., 6., 6., 6., 6., 6., 5., 6., 5., 6., 7., 5., 6.,
       6., 6., 5., 7., 6., 6., 6., 7., 6., 5., 5., 7., 5., 6., 7., 5., 6.,
       6., 5., 6., 6., 6., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 5., 5.,
       5., 5., 5., 6., 6., 5., 6., 6., 5., 6., 5., 5., 6., 6., 6., 5., 5.,
       6., 6., 6., 5., 6., 6., 6., 5., 5., 5., 6., 5., 6., 6., 6., 6., 7.,
       6., 6., 5., 5., 5., 5., 6., 5., 6., 5., 5., 6., 5., 5., 5., 5., 6.,
       6., 5., 5., 5., 6., 5., 7., 5., 6., 5., 5., 5., 5., 6., 7., 6., 6.,
       6., 6., 6., 6., 6., 5., 7., 6., 5., 7., 6., 6., 6., 5., 6., 5., 6.,
       6., 6., 5., 6., 5., 5., 6., 6., 5., 5., 5., 6., 5., 5., 6., 6., 6.,
       5., 5., 6., 5., 6., 6., 5., 5., 5., 7., 6., 6., 5., 6.])
accuracy_score(test_y, pread_y4)
0.6375
Lin.score(train_x, train_y)
0.3623540484518224
mae(test_y, pread_y4)
0.390625
from sklearn.metrics import r2_score
r2_score(test_y, pread_y)
0.3283887639580255
